{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Sequential Labelling Lora"]},{"cell_type":"markdown","metadata":{},"source":["## Import Modules"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T08:02:22.377469Z","iopub.status.busy":"2023-10-25T08:02:22.377095Z","iopub.status.idle":"2023-10-25T08:02:35.175370Z","shell.execute_reply":"2023-10-25T08:02:35.174238Z","shell.execute_reply.started":"2023-10-25T08:02:22.377438Z"},"trusted":true},"outputs":[],"source":["!pip install -q evaluate nusacrowd seqeval peft\n","import evaluate\n","import numpy as np\n","import transformers\n","import tensorflow as tf\n","import pandas as pd\n","import torch\n","import wandb\n","\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, DataCollatorForTokenClassification, create_optimizer, TFAutoModelForTokenClassification, pipeline\n","from IPython.display import display, HTML\n","from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-25T08:10:45.648806Z","iopub.status.idle":"2023-10-25T08:10:45.649163Z","shell.execute_reply":"2023-10-25T08:10:45.649008Z","shell.execute_reply.started":"2023-10-25T08:10:45.648992Z"},"trusted":true},"outputs":[],"source":["from kaggle_secrets import UserSecretsClient\n","\n","user_secrets = UserSecretsClient()\n","\n","my_secret = user_secrets.get_secret(\"wandb_api_key\") \n","\n","wandb.login(key=my_secret)\n","wandb.init(entity = \"adiyansawicaksana\", project = \"huggingface\")"]},{"cell_type":"markdown","metadata":{},"source":["## Import Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:00.477287Z","iopub.status.busy":"2023-10-25T07:58:00.476916Z","iopub.status.idle":"2023-10-25T07:58:05.807484Z","shell.execute_reply":"2023-10-25T07:58:05.806572Z","shell.execute_reply.started":"2023-10-25T07:58:00.477252Z"},"trusted":true},"outputs":[],"source":["nergrit = load_dataset('NusaCrowd/nergrit')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:05.808911Z","iopub.status.busy":"2023-10-25T07:58:05.808622Z","iopub.status.idle":"2023-10-25T07:58:05.815875Z","shell.execute_reply":"2023-10-25T07:58:05.814975Z","shell.execute_reply.started":"2023-10-25T07:58:05.808886Z"},"trusted":true},"outputs":[],"source":["print(nergrit[\"train\"][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:05.817253Z","iopub.status.busy":"2023-10-25T07:58:05.816979Z","iopub.status.idle":"2023-10-25T07:58:06.290931Z","shell.execute_reply":"2023-10-25T07:58:06.289963Z","shell.execute_reply.started":"2023-10-25T07:58:05.817224Z"},"trusted":true},"outputs":[],"source":["# Extract the 'ner_tag' column from the training set\n","ner_tags_list = nergrit[\"train\"][\"ner_tag\"]\n","\n","# Flatten the list of lists\n","flattened_ner_tags = [tag for sublist in ner_tags_list for tag in sublist]\n","\n","# Get the unique labels\n","unique_labels = list(set(flattened_ner_tags))\n","\n","print(unique_labels)"]},{"cell_type":"markdown","metadata":{},"source":["Based on the documentation in https://huggingface.co/datasets/NusaCrowd/nergrit.\n","<br>\n","Label:\n","\n","'CRD': Cardinal\n","\n","'DAT': Date\n","\n","'EVT': Event\n","\n","'FAC': Facility\n","\n","'GPE': Geopolitical Entity\n","\n","'LAW': Law Entity (such as Undang-Undang)\n","\n","'LOC': Location\n","\n","'MON': Money\n","\n","'NOR': Political Organization\n","\n","'ORD': Ordinal\n","\n","'ORG': Organization\n","\n","'PER': Person\n","\n","'PRC': Percent\n","\n","'PRD': Product\n","\n","'QTY': Quantity\n","\n","'REG': Religion\n","\n","'TIM': Time\n","\n","'WOA': Work of Art\n","\n","'LAN': Language"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:06.292586Z","iopub.status.busy":"2023-10-25T07:58:06.292212Z","iopub.status.idle":"2023-10-25T07:58:06.299955Z","shell.execute_reply":"2023-10-25T07:58:06.298950Z","shell.execute_reply.started":"2023-10-25T07:58:06.292551Z"},"trusted":true},"outputs":[],"source":["labels_dict = {\n","    'O': 0,\n","    'B-CRD': 1, 'I-CRD': 2,\n","    'B-DAT': 3, 'I-DAT': 4,\n","    'B-EVT': 5, 'I-EVT': 6,\n","    'B-FAC': 7, 'I-FAC': 8,\n","    'B-GPE': 9, 'I-GPE': 10,\n","    'B-LAW': 11, 'I-LAW': 12,\n","    'B-LOC': 13, 'I-LOC': 14,\n","    'B-MON': 15, 'I-MON': 16,\n","    'B-NOR': 17, 'I-NOR': 18,\n","    'B-ORD': 19, 'I-ORD': 20,\n","    'B-ORG': 21, 'I-ORG': 22,\n","    'B-PER': 23, 'I-PER': 24,\n","    'B-PRC': 25, 'I-PRC': 26,\n","    'B-PRD': 27, 'I-PRD': 28,\n","    'B-QTY': 29, 'I-QTY': 30,\n","    'B-REG': 31, 'I-REG': 32,\n","    'B-TIM': 33, 'I-TIM': 34,\n","    'B-WOA': 35, 'I-WOA': 36,\n","    'B-LAN': 37, 'I-LAN': 38\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:06.301493Z","iopub.status.busy":"2023-10-25T07:58:06.301213Z","iopub.status.idle":"2023-10-25T07:58:07.514432Z","shell.execute_reply":"2023-10-25T07:58:07.513403Z","shell.execute_reply.started":"2023-10-25T07:58:06.301469Z"},"trusted":true},"outputs":[],"source":["# use IndoBERT\n","tokenizer = AutoTokenizer.from_pretrained('indolem/indobert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:07.516083Z","iopub.status.busy":"2023-10-25T07:58:07.515772Z","iopub.status.idle":"2023-10-25T07:58:07.534397Z","shell.execute_reply":"2023-10-25T07:58:07.533609Z","shell.execute_reply.started":"2023-10-25T07:58:07.516057Z"},"trusted":true},"outputs":[],"source":["example = nergrit[\"train\"][0]\n","tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n","tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n","tokens[:10]"]},{"cell_type":"markdown","metadata":{},"source":["Based on the documentation:\n","\n","> This adds some special tokens [CLS] and [SEP] and the subword tokenization creates a mismatch between the input and labels. A single word corresponding to a single label may now be split into two subwords. You'll need to realign the tokens and labels by:\n","\n","1. Mapping all tokens to their corresponding word with the word_ids method.\n","2. Assigning the label -100 to the special tokens [CLS] and [SEP] so they're ignored by the PyTorch loss function.\n","3. Only labeling the first token of a given word. Assign -100 to other subtokens from the same word.\n","\n","So it is needed to realign the token and labels, and truncate the sequence if it is longer than the models maximum length"]},{"cell_type":"markdown","metadata":{},"source":["Based on the reference:\n","\n","> It's more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length.\n","\n","So, creating the data collator."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:07.538061Z","iopub.status.busy":"2023-10-25T07:58:07.537759Z","iopub.status.idle":"2023-10-25T07:58:07.548469Z","shell.execute_reply":"2023-10-25T07:58:07.547488Z","shell.execute_reply.started":"2023-10-25T07:58:07.538036Z"},"trusted":true},"outputs":[],"source":["# Rename the 'labels' column to 'ner_tag'\n","nergrit[\"train\"] = nergrit[\"train\"].rename_column(\"ner_tag\", \"labels\")\n","nergrit[\"validation\"] = nergrit[\"validation\"].rename_column(\"ner_tag\", \"labels\")\n","nergrit[\"test\"] = nergrit[\"test\"].rename_column(\"ner_tag\", \"labels\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:07.549966Z","iopub.status.busy":"2023-10-25T07:58:07.549656Z","iopub.status.idle":"2023-10-25T07:58:07.557396Z","shell.execute_reply":"2023-10-25T07:58:07.556626Z","shell.execute_reply.started":"2023-10-25T07:58:07.549940Z"},"trusted":true},"outputs":[],"source":["def tokenize_and_align_labels(dataset):\n","    tokenized_inputs = tokenizer(dataset[\"tokens\"], truncation=True, is_split_into_words=True)\n","\n","    labels = []\n","    for i, labels_per_example in enumerate(dataset[\"labels\"]):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:  # Set the special tokens to -100.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n","                token_labels = [labels_dict[label] for label in labels_per_example]\n","                label_ids.append(token_labels[word_idx])\n","            else:\n","                label_ids.append(-100)\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:07.558744Z","iopub.status.busy":"2023-10-25T07:58:07.558454Z","iopub.status.idle":"2023-10-25T07:58:12.776417Z","shell.execute_reply":"2023-10-25T07:58:12.775549Z","shell.execute_reply.started":"2023-10-25T07:58:07.558699Z"},"trusted":true},"outputs":[],"source":["tokenized_nergrit = nergrit.map(tokenize_and_align_labels, batched=True) #processing in batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:12.777772Z","iopub.status.busy":"2023-10-25T07:58:12.777491Z","iopub.status.idle":"2023-10-25T07:58:12.782334Z","shell.execute_reply":"2023-10-25T07:58:12.781339Z","shell.execute_reply.started":"2023-10-25T07:58:12.777748Z"},"trusted":true},"outputs":[],"source":["data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=\"tf\")"]},{"cell_type":"markdown","metadata":{},"source":["## Metrics Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["I will be using just accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:12.783841Z","iopub.status.busy":"2023-10-25T07:58:12.783544Z","iopub.status.idle":"2023-10-25T07:58:13.503789Z","shell.execute_reply":"2023-10-25T07:58:13.502942Z","shell.execute_reply.started":"2023-10-25T07:58:12.783817Z"},"trusted":true},"outputs":[],"source":["seqeval = evaluate.load(\"seqeval\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:13.505459Z","iopub.status.busy":"2023-10-25T07:58:13.505189Z","iopub.status.idle":"2023-10-25T07:58:13.512216Z","shell.execute_reply":"2023-10-25T07:58:13.511175Z","shell.execute_reply.started":"2023-10-25T07:58:13.505434Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(p):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    true_predictions = [\n","        [unique_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [unique_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"accuracy\": results[\"overall_accuracy\"],\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["## Fine-Tuning the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:13.514009Z","iopub.status.busy":"2023-10-25T07:58:13.513627Z","iopub.status.idle":"2023-10-25T07:58:13.525192Z","shell.execute_reply":"2023-10-25T07:58:13.524411Z","shell.execute_reply.started":"2023-10-25T07:58:13.513974Z"},"trusted":true},"outputs":[],"source":["labels = list(labels_dict.keys())\n","\n","id2label = {i: label for i, label in enumerate(labels)}\n","label2id = {label: i for i, label in id2label.items()}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:13.526616Z","iopub.status.busy":"2023-10-25T07:58:13.526353Z","iopub.status.idle":"2023-10-25T07:58:13.538159Z","shell.execute_reply":"2023-10-25T07:58:13.537206Z","shell.execute_reply.started":"2023-10-25T07:58:13.526593Z"},"trusted":true},"outputs":[],"source":["len(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:58:13.540190Z","iopub.status.busy":"2023-10-25T07:58:13.539518Z","iopub.status.idle":"2023-10-25T07:58:13.556205Z","shell.execute_reply":"2023-10-25T07:58:13.554947Z","shell.execute_reply.started":"2023-10-25T07:58:13.540154Z"},"trusted":true},"outputs":[],"source":["batch_size = 16\n","num_train_epochs = 3\n","num_train_steps = (len(tokenized_nergrit[\"train\"]) // batch_size) * num_train_epochs\n","optimizer, lr_schedule = create_optimizer(\n","    init_lr=2e-5,\n","    num_train_steps=num_train_steps,\n","    weight_decay_rate=0.01,\n","    num_warmup_steps=0,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:59:12.759294Z","iopub.status.busy":"2023-10-25T07:59:12.758879Z","iopub.status.idle":"2023-10-25T07:59:23.886097Z","shell.execute_reply":"2023-10-25T07:59:23.885364Z","shell.execute_reply.started":"2023-10-25T07:59:12.759259Z"},"trusted":true},"outputs":[],"source":["model = TFAutoModelForTokenClassification.from_pretrained(\n","    \"indolem/indobert-base-uncased\", \n","    num_labels=39,          # set the num labels to 39\n","    id2label=id2label, \n","    label2id=label2id, \n","    from_pt=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:59:27.865481Z","iopub.status.busy":"2023-10-25T07:59:27.865098Z","iopub.status.idle":"2023-10-25T07:59:28.479610Z","shell.execute_reply":"2023-10-25T07:59:28.478857Z","shell.execute_reply.started":"2023-10-25T07:59:27.865449Z"},"trusted":true},"outputs":[],"source":["tf_train_set = model.prepare_tf_dataset(\n","    tokenized_nergrit[\"train\"],\n","    shuffle=True,\n","    batch_size=batch_size,\n","    collate_fn=data_collator,\n",")\n","\n","tf_validation_set = model.prepare_tf_dataset(\n","    tokenized_nergrit[\"validation\"],\n","    shuffle=False,\n","    batch_size=batch_size,\n","    collate_fn=data_collator,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T07:59:32.374234Z","iopub.status.busy":"2023-10-25T07:59:32.373620Z","iopub.status.idle":"2023-10-25T07:59:32.394987Z","shell.execute_reply":"2023-10-25T07:59:32.394120Z","shell.execute_reply.started":"2023-10-25T07:59:32.374201Z"},"trusted":true},"outputs":[],"source":["model.compile(optimizer=optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T08:06:31.106257Z","iopub.status.busy":"2023-10-25T08:06:31.105853Z","iopub.status.idle":"2023-10-25T08:06:35.381314Z","shell.execute_reply":"2023-10-25T08:06:35.379591Z","shell.execute_reply.started":"2023-10-25T08:06:31.106223Z"},"trusted":true},"outputs":[],"source":["# create the callback for the model\n","metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)\n","\n","push_to_hub_callback = PushToHubCallback(\n","    output_dir=\"indobert-base-uncased-finetuned-nergrit\",  # change this based on the output repo desired\n","    tokenizer=tokenizer,\n",")\n","\n","wandb_callback = wandb.keras.WandbCallback()\n","\n","callbacks = [metric_callback, push_to_hub_callback, wandb_callback]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T08:06:43.120923Z","iopub.status.busy":"2023-10-25T08:06:43.120484Z","iopub.status.idle":"2023-10-25T08:10:45.647949Z","shell.execute_reply":"2023-10-25T08:10:45.646166Z","shell.execute_reply.started":"2023-10-25T08:06:43.120888Z"},"trusted":true},"outputs":[],"source":["model.fit(x=tf_train_set, \n","          validation_data=tf_validation_set, \n","          epochs=25,                 \n","          callbacks=callbacks)"]},{"cell_type":"markdown","metadata":{},"source":["## Inferencing the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:58:14.898415Z","iopub.status.idle":"2023-10-25T07:58:14.898886Z","shell.execute_reply":"2023-10-25T07:58:14.898650Z","shell.execute_reply.started":"2023-10-25T07:58:14.898629Z"},"trusted":true},"outputs":[],"source":["text = \"\"\"Jakarta, Maret 1998\n","Di sebuah senja, di sebuah rumah susun di Jakarta, mahasiswa bernama Biru Laut disergap empat lelaki tak dikenal. Bersama kawan-kawannya, Daniel Tumbuan, Sunu Dyantoro, Alex Perazon, dia dibawa ke sebuah tempat yang tak dikenal. Berbulan-bulan mereka disekap, diinterogasi, dipukul, ditendang, digantung, dan disetrum agar bersedia menjawab satu pertanyaan penting: siapakah yang berdiri di balik gerakan aktivis dan mahasiswa saat itu.\n","Jakarta, Juni 1998\n","Keluarga Arya Wibisono, seperti biasa, pada hari Minggu sore memasak bersama, menyediakan makanan kesukaan Biru Laut. Sang ayah akan meletakkan satu piring untuk dirinya, satu piring untuk sang ibu, satu piring untuk Biru Laut, dan satu piring untuk si bungsu Asmara Jati. Mereka duduk menanti dan menanti. Tapi Biru Laut tak kunjung muncul.\n","Jakarta, 2000\n","Asmara Jati, adik Biru Laut, beserta Tim Komisi Orang Hilang yang dipimpin Aswin Pradana mencoba mencari jejak mereka yang hilang serta merekam dan mempelajari testimoni mereka yang kembali. Anjani, kekasih Laut, para orangtua dan istri aktivis yang hilang menuntut kejelasan tentang anggota keluarga mereka. Sementara Biru Laut, dari dasar laut yang sunyi bercerita kepada kita, kepada dunia tentang apa yang terjadi pada dirinya dan kawan-kawannya.\n","Laut Bercerita, novel terbaru Leila S. Chudori, bertutur tentang kisah keluarga yang kehilangan, sekumpulan sahabat yang merasakan kekosongan di dada, sekelompok orang yang gemar menyiksa dan lancar berkhianat, sejumlah keluarga yang mencari kejelasan akan anaknya, dan tentang cinta yang tak akan luntur.\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:58:14.900229Z","iopub.status.idle":"2023-10-25T07:58:14.900663Z","shell.execute_reply":"2023-10-25T07:58:14.900459Z","shell.execute_reply.started":"2023-10-25T07:58:14.900438Z"},"trusted":true},"outputs":[],"source":["# use pipeline to easen inferencing the model\n","classifier = pipeline(\"ner\", model=\"apwic/indobert-base-uncased-finetuned-nergrit\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:58:14.902604Z","iopub.status.idle":"2023-10-25T07:58:14.902953Z","shell.execute_reply":"2023-10-25T07:58:14.902805Z","shell.execute_reply.started":"2023-10-25T07:58:14.902789Z"},"trusted":true},"outputs":[],"source":["classified_text = classifier(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:58:14.904102Z","iopub.status.idle":"2023-10-25T07:58:14.904554Z","shell.execute_reply":"2023-10-25T07:58:14.904338Z","shell.execute_reply.started":"2023-10-25T07:58:14.904316Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame(classified_text[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:58:14.906235Z","iopub.status.idle":"2023-10-25T07:58:14.906567Z","shell.execute_reply":"2023-10-25T07:58:14.906421Z","shell.execute_reply.started":"2023-10-25T07:58:14.906405Z"},"trusted":true},"outputs":[],"source":["def visualize_entities_html(text, classified_text):\n","    # Create a color mapping for each entity type\n","    color_map = {\n","        'GPE': 'yellow',\n","        'DAT': 'blue',\n","        'PER': 'green',\n","        'CRD': 'red',\n","        'EVT': '#FFA500',  # orange\n","        'FAC': '#FFC0CB',  # pink\n","        'LAW': '#FFD700',  # gold\n","        'LOC': '#ADFF2F',  # greenyellow\n","        'MON': '#FA8072',  # salmon\n","        'NOR': '#9370DB',  # mediumpurple\n","        'ORD': '#7B68EE',  # mediumslateblue\n","        'ORG': '#6A5ACD',  # slateblue\n","        'PRC': '#FF69B4',  # hotpink\n","        'PRD': '#D2B48C',  # tan\n","        'QTY': '#FF6347',  # tomato\n","        'REG': '#DB7093',  # palevioletred\n","        'TIM': '#EEE8AA',  # palegoldenrod\n","        'WOA': '#F08080',  # lightcoral\n","        'LAN': '#BDB76B'   # darkkhaki\n","    }\n","\n","    \n","    # Sort classified_text by start index\n","    classified_text.sort(key=lambda x: x['start'])\n","\n","    html_output = text\n","    shift = 0\n","    \n","    for entity in classified_text:\n","        word = entity['word']\n","        start = entity['start'] + shift\n","        end = entity['end'] + shift\n","        entity_type = entity['entity'].split('-')[-1]  # Extracting main entity type e.g., 'B-GPE' -> 'GPE'\n","        color = color_map.get(entity_type, 'grey')  # Default to grey if entity type is not in our map\n","        \n","        # Wrap the word in a span with background color\n","        span = f\"<span style='background-color: {color}'>{word}</span>\"\n","        \n","        # Replace the word in the text with the highlighted word\n","        html_output = html_output[:start] + span + html_output[end:]\n","        \n","        # Adjust shift based on the added HTML tags\n","        shift += len(span) - (end - start)\n","    \n","    display(HTML(html_output))\n","\n","visualize_entities_html(text, classified_text)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
